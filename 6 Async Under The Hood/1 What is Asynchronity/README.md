# Что такое асинхронность

## Кооперативная многозадачность

Мы уже говорили про потоки и процессы - средства, позволяющие одновременно с течением программы выполнить какую-то дополнительную работу.

Минус процессов и тредов в том, что это безумно тяжелые объекты. Поэтому нельзя создавать много процессов или тредов одновременно - банально не хватит памяти.

Сейчас мы разберемся, как происходит создание нового процесса на уровне операционной системы.

### Старт процессов

В Linux и MacOS старт процесса осуществляется с помощью двух системных вызовов. В Windows свои интересные штуки, но все это близко и похоже по реализации.

Всегда есть родительский процесс, запускающий другой процесс. Если мы запускаем Python, родительским процессом всегда является bash, то есть, наша командная строка.

При старте системы существует один единственныей процесс, который имеет id 1. Он и является родительским процессом для всех остальных.

### Fork и Exec

Задача fork в том, чтобы отоединиться от текущего процесса. Отсоединение означает, что вся память процесса копируется в новую сущность, которая затем может продолжить существовать.

Вызов в exec заменяет текущий контекст выполнения новой сущности другой программой.

Например, в терминале мы вызывали функцию find:

1. Произошел вызов fork - вся память процесса терминала скопировалась в новый созданный процесс.
2. Произошел вызов exec - текущий контекст выполнения (то есть терминал) сменился на контекст выполнения программы find.
3. find теперь выполняется в другом дочернем для терминала процессе.

Создание нового процесса - это очень долгое и очень дорогое по памяти явление.

### Потоки

Потоки как будто решают проблему с памятью и временем создания. Их дешевле создавать, и они находятся в рамках одного процесса. Но это не лучшее решение проблемы: запуск одного потока означает копирование состояния процесса, потому что ему все равно нужно создать какие-то структуры.

Это гораздо быстрее но нельзя создать, например, 1000 полноценно-рабощих потоков, если процессор не состоит из 1000 ядер.

Для работы потока в полную силу ему нужно отдельное ядро процессора. Чаще всего в одном процессе запускают не так много потоков. Например, если работает какой-то веб-сервер, там запускает число потоков, равное числу ядер - либо чуть больше.

### Асинхронный подход

Допустим мы хотим скачать весь сайт. Например, всю Википедию.

Мы получили список ссылок, который состоит из 1,000,000 документов. Если мы хотим сделать это как можно быстрее, то попробуем создать 1,000,000 потоков и быстро все скачать.

Но так не получится: во-первых, мы упремся в память, потому что потоки много весят в оперативной памяти; во-вторых, даже если бы все они влезли, процессор не смогу бы обеспечить нормальный квант времени каждому из потоков. Кому-то придется ждать и достаточно долго. Скорее всего на 4-ядерной системе будут работать 4-8 потоков, и все остальные будут просто по очереди ждать и завершаться.

Тут нам на помощь приходит асинхронный подход: идея в том, чтобы не ждать какой-то операции, а доверить это ожидание кому-то другому.

Теперь давайте разберемся, как вообще работать с сетью без библиотек requests и aiohttp, чтобы подойти к идее асинхронного программирования.

## Как работать с сетью с помощью сокетов?

Допустим, мы делаем поисковик.

Задача любого поисковика - при вводе текста запроса выдать какие-то релевантные сайты, чтобы поисковик построил индекс.

Поисковик должен обкачать эти сайты, понять, что за текст там написан, построить обратный индекс и дальше по словам пользователя возвращать сайты, которые удоволетворяют поиску.

Алгоритм работы веб-браузера, который занимается обкачкой сайтов достаточно простой. У него есть список url адресов, которые необходимо скачать первоначально. Мы берем эти сайты и начинаем с их корня. Получаем HTML-странички этих сайтов и анализируем каждую.

Наша задача - вытащить текст с каждой страницы и найти связанный url с каждой страницы. То есть, мы парсим теги `<a>`, содержащие ссылки на другие ресурсы. Тем самым мы обогащаем список url адресов.

После этого повторяем эти же действия. Идем по большему количеству адресов, и так мы можем спускаться до бесконечности.

Точный алгоритм чуть сложнее и больше, но поверхностно он выглядит примерно так:

1. Первоначальный список URL, которые необходимо скачать
2. Скачивание страниц из списка URL
3. Анализ каждой страницы
4. Поиск связанных URL
5. Повторить с пункта #2

Пример. Здесь достаточно простой низкоуровневый код, чтобы потом нам было чуть проще рассмотреть ввод-вывод. Здесь код подключается к какому-то ресуру и выполняет HTTP GET-запрос:

```python
import socket

q = ...

def fetch(url: str):
    sock = socket.socket()
    sock.connect(('abcd.com', 80))
    request = f'GET {url} HTTP/1.0\r\nHost: abcd.com\r\n\r\n'
    sock.send(request.encode('ascii'))
    response = b''
    chunk = sock.recv(4096)
    while chunk:
        response += chunk
        chunk = sock.recv(4096)
    links = parse_links(response)
    q.update(links)
```

Разберемся, что происходит в этом примере:

1. Создается сущность `socket`. Это пара IP-порт, которая подключена к другой паре IP-порт, и между ними создан какой-то канал, по которому в обе стороны бегают данные.
2. Происходит системный вызов `connect()`.
3. Составляем текст нашего запроса. Помним, что HTTP - это текстовый протокол.
4. Делаем системный вызов `sock.send()`, куда отправляем наш запрос.
5. Последние строчки считывают ответ, то есть, HTTP-сервер на домене abcd.com получил наш запрос и отвечает тоже HTTP-ответом. Мы собираем этот ответ с помощью системного вызова `chunk = sock.recv(4096)`, пока не получим все данные - то есть пока сокет не вернет пустой ответ.

Проблема такого кода: мы читаем ответ до тех пор, пока он не закончится. А это значит, что мы ничего не можем сделать в этот момент. Если мы хотим обкачать 1,000,000 страниц с помощью такого подхода то бдуем делать это последовательно и очень долго.

### Решения

Треды и потоки. Это первый способ решения проблемы, про который мы уже говорили.

Все перечисленные операции - `connect`, `send`, `receive` - блокирующие.

`connect` будет блокировать выполнение скрипта до тех пор, пока не осуществит успешное или неуспешное подключение. Сервер может ему ответить connection refused, и тогда он отправит ошибку, что подключиться не удалось.

Более яркий пример - `receive`. У нас есть данные на вашем компьютере, и мы отправляем их на удаленный сервер. Данные не перемещаются мгновенно, поэтому у нас есть время ожидания, пока данные находятся на нашей сетевой карте ил ина удаленной сетевой карте.

Это означает, что когда наш удаленный сервер отправил какие-то данные, мы сидим и ждем. Наши данные где-то летят - условно, через Америку, через океаны - и приходят, через период времени. Пока данных нет, код заблокирован. Он ждет, пока они появятся, чтобы их вычитать. А ведь вместо этого мы могли бы заняться чем-то полезным во время ожидания: распарсить другой сайт, сходить на другой домен и т.д.

<b>Неблокирующий ввод-вывод</b>. Наша цель - сделать так, чтобы мы не блокировались во время сетевой операции или любой другой операции ввода-вывода. Вводом-выводом считается чтение с диска, работа с сетью и многое другое.

Есть так называемая проблема C10k: как один сервер может одновременно работать с 10,000 соединениями?

Чтобы один сервер мог эффективно обслуживать такое количество соединений, используется неблокирующий ввод-вывод и асинхронное программирование.

Пример неблокирующего сокета:

```python
sock = socket.socket()
sock.setblocking(False)
try:
    sock.connect(('abcd.com', 80))
except BlockingIOError:
    pass
```

Неблокирующий ввод-вывод делается флагом `sock.setblocking(false)`, то есть, мы просто говорим сокету не быть блокирующим. Но все не так просто.

Действие `sock.setblocking(false)` означает, что если мы попытаемся выполнить какое-то действие, которое приведет к блокировке, у нас выбросится исключение.

Например, мы попытаемся что-то прочитать из сокета, а данных на сетевой карте нет. Тогда метод `socket.recv` выкинет исключение `BlockingIOError`. В случае блокирующего сокета код заблокируется, а не выкинет исключение.

### Плохой вариант неблокирующего сокета

Смотри `1_bad_socket.py`

У нас есть запрос, который мы пытаемся отправить в наш неблокирующий сокет.

Сокет на запись может быть недоступен. Например, буфер в нашей сетевой карте полностью заполнен. Или мы еще не успели установить соединение, не выполнился TCP-handshake. Идея в том, что сокет может быть недоступен на запись в данный момент времени так же, как может быть недоступен на чтение. Он заблокируется, о чем сообщит ОС, выкинув `OSError` или его наследника `BlockingIOException`.

Мы хотим уметь делать какие-то дополнительные действия в моменты, когда у нас потенциально произойдет блокировка. То есть, в целом мы могли бы что-то делать внутри этого исключения.

Но отправить данные тоже нужно, поэтому мы все равно зависим от этого сокета. Мы будем на самом деле пытаться отправить данные до тех пор, пока у нас не получится. И в целом - используя такой наивный подход, мы не можем сделать ничего лучше того, что написано в примере.

То есть, мы сделали сокет неблокирующим, и он не заблокирует код. Но вместо этого мы получим ошибку, которую никак не можем отработать, потому что данные отправить все равно нужно. Так что мы будем так и крутиться в цикле до тех пора, пока не отправим данные.

<b>Проблема такого пути:</b> хотя сокет неблокирующий, мы все равно должны ждать завершения цикла.

На самом деле стало еще хуже, чем было. Когда сокет был блокирующий, мы сделали `sock.send`, и операционная система взяла на себя обязанность отправить эти данные. Сами мы уснули: ждем сигнала от ОС, что все завершилось успешно.

Но в этом примере с неблокирующим сокетом ОС сразу отвечает: "Я сейчас заблокируюсь и ничего отправлять не буду". И мы начнинаем крутиться в `while True`, пока в итоге не окажется, что наш процесс потребляет 100% CPU. Он будет просто греть ядро, потому что наш код - бесконечный цикл, который пытается выполнить какую-то операцию, которая сразу завершается с ошибкой.

Мы можем сделать множество сокетов на кучу разных доменов и пытаться поочередно сделать разные `send`. Они будут давать исключения, а мы будем как-то их ретраить. Можно ретраить их все одновременно: пройтись по ним всем циклом, сделать `send`. Увидим, что у кого-то получилось, а у кого-то нет, то есть надо делать `try-except` над каждым из них.

Резюме вышенаписанного: хотя сокет в примере неблокирующий, но сам весь код оказался блокирующим - он потребляет 100% CPU и бесконечно пытается послать данные или считать их из сокета. Как же сделать правильно? Разберемся в следующем разделе.

## Хороший вариант неблокирующего сокета

Этот вариант называется select.

У ОС в Unix, также как в Linux и MacOS, есть несколько примитивов, которые позволяют выполнить очень хитрые действия.

Эти хитрые команды мы можем выполнить в терминале:

-   select
-   poll
-   epoll (Linux)
-   kqueue (FreeBSD, MacOS)

### Функции команд

Сокет - это просто номер файлового дескриптора, который ОС выделила нам при создании сокета. Когда вы откроете файл (а сокет такой же файл), ОС внутри у себя в ядре создает сущность и выдает вам ответ уникальный для текущего процесса идентификатор этой сущности: обычное число типа 3, 4 или 5.

Мы можем попросить ОС сообщать нам об изменении состояния того или иного файлового дескриптора. Условно, мы просим: "Если в дескриптор под номером 5 придет какая-то информация, и он станет доступен на чтение, сообщи мне пожалуйста". Наша программа пока может спать, а не бесконечно крутиться в цикле. Как только событие произойдет, ОС сама вызовет нужную часть программы и тем самым продолжит ее выполнение.

### Различия между командами

Select - самая старая команда и поддерживает только 1024 файловых дескриптора, когда poll поддерживает гораздо больше.
Epoll и kqueue являются более совершенными технологиями и являются аналогами друг друга. Если система не поддерживает epoll, она скатывается до poll, если же не поддерживает poll, то скатывается до select.

По реззультату работы эти команды не отличаются. На вход они принимают файловые дескрипторы и вызывают какую-то логику при наступлении определенных событий в этих дескрипторах.

Смотри `2_good_socket.py`

Разберем, что происходит в примере выше:

DefaultSelector - это класс, возвращающий лучший из доступных механизмов на операционной системе. Вот как это работает:

```python
if _can_use('kqueue'):
    DefaultSelector = KqueueSelector
elif _can_use('epoll'):
    DefaultSelector = EpollSelector
elif _can_use('devpoll'):
    DefaultSelector = DevpollSelector
elif _can_use('poll'):
    DefaultSelector = PollSelector
else:
    DefaultSelector = SelectSelector
```

Далее, мы создали сокет и выполнили подключение к abcd.com. В этот момент у нас выбросилось исключение `BlockingIOError` - подключение все еще выполняется, но нам это сейчас не важно. Просто идем дальше, ничего не делая с исключением.

Дальше мы подписываемся на определенное событие в сокете. То есть говорим ОС: если этот сокет станет доступен на запись, то сообщи, пожалуйста, мне и вызови функцию `callback`.

Event Loop, или цикл событий - это цикл, который бесконечно ожидает появления каких-то событий и выолняет нужную часть программы при их возникновении. Он не проверяет постоянно наличие событий сам (в отличие от предыдущего плохого примера), а блокируется и ждет, пока ОС сообщит ему о наличии таких событий. Так он не нагружает CPU ненужными операциями.

Мы запустили `while True` и заблокировались на строчке `event = selector.select()`. Как только соединение с нашим сокетом установится, `select()` вернет какие-то события (в нашем случае только одно событие).

Из чего состоят возвращаемые select() события?

Events - это список, состоящий из кортежей длины 2. Первым элементом в картеже идет `event_ky` - объект, который содержит сокет, на котором произошло событие, и callback-функцию, зарегистрированную на это событие на этом сокете. Вторым элементом в кортеже идет `event_mask` - число 1, 2 или 3. Переводя эти числа в двоичный вид, получим 01, 10 или 11 соответсвенно. Это маска события, произошедшего на сокете:

-   EventWrite (доступность сокета на запись) - 01
-   EventRead (доступность сокета на чтение) - 10
-   EventWrite | EventRead (доступность сокета как на чтение, так и на запись) - 10 | 01 = 11

Повторим:

1. Мы начали подключение к сокету.
2. Подписались на событие достпуности сокета на запись.
3. Запустили бесконечный цикл.
4. Заблокировались и стали дожидаться, пока нужное событие произойдет, и ОС сообщит нам об этом.
5. Выполнили callback-функцию, привязанную к этому сокету и этому событию.

Так и получается асинхронность. Мы начали выполнять операцию в один момент времени, а потом в другой - неподконтрольный нам - происходит выполнение другой функции. В следующем разделе мы рассмотрим, что такое асинхронность.

## Конкурентность и параллельность

![parallel_concurrent](/static/parallel_concurrent.png)

В параллельности у нас есть задача 1 и задача 2, и они могут быть распределены на 2 разных ядра. В конкурентности же каждая из этих задач может быть поделена на какие-то небольшие подзадачи, которые могут перемещаться с одного ядро на другое.

Одно из подходов к асинхронной парадигме, который мы уже немного использовали - применение callback-функций. То есть, при наступлении какого-то события вызывается связанная с ним callback-функция.

Пример:

![parallel_concurrent](/static/callback_example.png)

Разберем, что происходит в схеме выше:

У нас есть функция `fetch`, которая скачивает HTML-документ.

Она выполняет вызов `connect`. После `connect` должен был вызваться callback `connected`, в тот момент когда мы уверены, что у нас действительно установлено соединение Именно этот момент означает, что мы можем отправить запрос в сокет. До наступления `connected` мы не можем отправить запрос - он упадет с ошибкой.

Как только произошел `connected`, внутри его callback-функции `connected`, мы можем сделать `send`. Но `send` тоже потенциально блокирующая операция, которая вернет исключение, если мы будем пытаться заблокироваться. Поэтому нужно так же подписаться на событие доступности сокета на чтение и так же сделать callback-функцию.

И так конечная функция `update_urls` может превратиться в псевдокод:

```python
def update_urls():
    def connected():
        def can_read():
            def can_write():
                sock.send()
            sock.recv()
            selector.register(sock, can_write)
        selector.register(sock, can_read)

    sock.connect()
    selector.register(sock, connected)
```

В конечном счете все это может превратиться в CallbackHell, когда за одним callback следует еще и еще, одним словом - бесконечная матрешка.

И для борьбы с этим беспорядком нам могут помочь короутины.

### Короутины

Принцип кооперативной многозадачности (cooperative multitasking) таков: мы в одном процессе пытаемся выполнить много задач. Противоположность кооперативной - вытесняющая многозадачность (preemptive multitasking).

Вытесняющая многозадачность - это то, как работают потоки и процессы. Работал один поток, пришла ОС, сняла его с ядра и поставила другой поток на какой-то период времени.

Короутины - функции, которые выполняются в рамках одного процесса.

Когда мы говорим, что мы поработаем в рамках одного процесса, и пытаемся что-то делать со множеством открытых соединений, короутин, которые должны как бы параллельно что-то запустить, мы говорим о кооперативной многозадачности. Смысл в том, что эти короутины и функции должны сами между собой договориться: когда будут выполняться одна, а когда другая.

Короутины есть во многих ЯП. Самый яркий пример - Go. Там есть горутины, которые еще называют подпрограммы или сопрограммы. По факту это то же самое. Разница в том, что горутины могут работать на разных потоках. Go запускает несколько рабочих потоков и может сам управлять графиком горутины между потоками, а в каждом потоке работает свой событийный цикл.

Мы сейчас рассматриваем Python, и у нас есть один поток, и в рамках этого процесса и потока у нас должежн работать набор короутин.

Самое большое достоинство короутин относительно потоков в том, что мы можем создать их невероятное количество - они очень легковесны. Короутина - просто функция, а функций может быть десятки и сотни тысяч одновременно. Если ваша программа написана таким образом, что она не позволяет на долгое время заблокироваться, она будет работать эффективно - управление будет передаваться между короутинами, которые дождались выполнения нужного им события, а остальные короутины будут просто спать

Короутины в Python 3 представлены библиотекой asyncio и синтаксисом async await. Но не подумайте, что если вы напишете async рядом с декларацией функции и await перед вызовом функции, код сразу станет асинхронным, быстрым и красивым. Все гораздо сложнее.

В следующем разделе уроке мы напишем свой Event Loop и попробуем наконец-то понять, как избежать CallbackHell и писать красивый, эффективный и простой асинхронный код.
