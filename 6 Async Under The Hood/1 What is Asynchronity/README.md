# Что такое асинхронность

## Кооперативная многозадачность

Мы уже говорили про потоки и процессы - средства, позволяющие одновременно с течением программы выполнить какую-то дополнительную работу.

Минус процессов и тредов в том, что это безумно тяжелые объекты. Поэтому нельзя создавать много процессов или тредов одновременно - банально не хватит памяти.

Сейчас мы разберемся, как происходит создание нового процесса на уровне операционной системы.

### Старт процессов

В Linux и MacOS старт процесса осуществляется с помощью двух системных вызовов. В Windows свои интересные штуки, но все это близко и похоже по реализации.

Всегда есть родительский процесс, запускающий другой процесс. Если мы запускаем Python, родительским процессом всегда является bash, то есть, наша командная строка.

При старте системы существует один единственныей процесс, который имеет id 1. Он и является родительским процессом для всех остальных.

### Fork и Exec

Задача fork в том, чтобы отоединиться от текущего процесса. Отсоединение означает, что вся память процесса копируется в новую сущность, которая затем может продолжить существовать.

Вызов в exec заменяет текущий контекст выполнения новой сущности другой программой.

Например, в терминале мы вызывали функцию find:

1. Произошел вызов fork - вся память процесса терминала скопировалась в новый созданный процесс.
2. Произошел вызов exec - текущий контекст выполнения (то есть терминал) сменился на контекст выполнения программы find.
3. find теперь выполняется в другом дочернем для терминала процессе.

Создание нового процесса - это очень долгое и очень дорогое по памяти явление.

### Потоки

Потоки как будто решают проблему с памятью и временем создания. Их дешевле создавать, и они находятся в рамках одного процесса. Но это не лучшее решение проблемы: запуск одного потока означает копирование состояния процесса, потому что ему все равно нужно создать какие-то структуры.

Это гораздо быстрее но нельзя создать, например, 1000 полноценно-рабощих потоков, если процессор не состоит из 1000 ядер.

Для работы потока в полную силу ему нужно отдельное ядро процессора. Чаще всего в одном процессе запускают не так много потоков. Например, если работает какой-то веб-сервер, там запускает число потоков, равное числу ядер - либо чуть больше.

### Асинхронный подход

Допустим мы хотим скачать весь сайт. Например, всю Википедию.

Мы получили список ссылок, который состоит из 1,000,000 документов. Если мы хотим сделать это как можно быстрее, то попробуем создать 1,000,000 потоков и быстро все скачать.

Но так не получится: во-первых, мы упремся в память, потому что потоки много весят в оперативной памяти; во-вторых, даже если бы все они влезли, процессор не смогу бы обеспечить нормальный квант времени каждому из потоков. Кому-то придется ждать и достаточно долго. Скорее всего на 4-ядерной системе будут работать 4-8 потоков, и все остальные будут просто по очереди ждать и завершаться.

Тут нам на помощь приходит асинхронный подход: идея в том, чтобы не ждать какой-то операции, а доверить это ожидание кому-то другому.

Теперь давайте разберемся, как вообще работать с сетью без библиотек requests и aiohttp, чтобы подойти к идее асинхронного программирования.

## Как работать с сетью с помощью сокетов?

Допустим, мы делаем поисковик.

Задача любого поисковика - при вводе текста запроса выдать какие-то релевантные сайты, чтобы поисковик построил индекс.

Поисковик должен обкачать эти сайты, понять, что за текст там написан, построить обратный индекс и дальше по словам пользователя возвращать сайты, которые удоволетворяют поиску.

Алгоритм работы веб-браузера, который занимается обкачкой сайтов достаточно простой. У него есть список url адресов, которые необходимо скачать первоначально. Мы берем эти сайты и начинаем с их корня. Получаем HTML-странички этих сайтов и анализируем каждую.

Наша задача - вытащить текст с каждой страницы и найти связанный url с каждой страницы. То есть, мы парсим теги `<a>`, содержащие ссылки на другие ресурсы. Тем самым мы обогащаем список url адресов.

После этого повторяем эти же действия. Идем по большему количеству адресов, и так мы можем спускаться до бесконечности.

Точный алгоритм чуть сложнее и больше, но поверхностно он выглядит примерно так:

1. Первоначальный список URL, которые необходимо скачать
2. Скачивание страниц из списка URL
3. Анализ каждой страницы
4. Поиск связанных URL
5. Повторить с пункта #2

Пример. Здесь достаточно простой низкоуровневый код, чтобы потом нам было чуть проще рассмотреть ввод-вывод. Здесь код подключается к какому-то ресуру и выполняет HTTP GET-запрос:

```python
import socket

q = ...

def fetch(url: str):
    sock = socket.socket()
    sock.connect(('abcd.com', 80))
    request = f'GET {url} HTTP/1.0\r\nHost: abcd.com\r\n\r\n'
    sock.send(request.encode('ascii'))
    response = b''
    chunk = sock.recv(4096)
    while chunk:
        response += chunk
        chunk = sock.recv(4096)
    links = parse_links(response)
    q.update(links)
```

Разберемся, что происходит в этом примере:

1. Создается сущность `socket`. Это пара IP-порт, которая подключена к другой паре IP-порт, и между ними создан какой-то канал, по которому в обе стороны бегают данные.
2. Происходит системный вызов `connect()`.
3. Составляем текст нашего запроса. Помним, что HTTP - это текстовый протокол.
4. Делаем системный вызов `sock.send()`, куда отправляем наш запрос.
5. Последние строчки считывают ответ, то есть, HTTP-сервер на домене abcd.com получил наш запрос и отвечает тоже HTTP-ответом. Мы собираем этот ответ с помощью системного вызова `chunk = sock.recv(4096)`, пока не получим все данные - то есть пока сокет не вернет пустой ответ.

Проблема такого кода: мы читаем ответ до тех пор, пока он не закончится. А это значит, что мы ничего не можем сделать в этот момент. Если мы хотим обкачать 1,000,000 страниц с помощью такого подхода то бдуем делать это последовательно и очень долго.

### Решения

Треды и потоки. Это первый способ решения проблемы, про который мы уже говорили.

Все перечисленные операции - `connect`, `send`, `receive` - блокирующие.

`connect` будет блокировать выполнение скрипта до тех пор, пока не осуществит успешное или неуспешное подключение. Сервер может ему ответить connection refused, и тогда он отправит ошибку, что подключиться не удалось.

Более яркий пример - `receive`. У нас есть данные на вашем компьютере, и мы отправляем их на удаленный сервер. Данные не перемещаются мгновенно, поэтому у нас есть время ожидания, пока данные находятся на нашей сетевой карте ил ина удаленной сетевой карте.

Это означает, что когда наш удаленный сервер отправил какие-то данные, мы сидим и ждем. Наши данные где-то летят - условно, через Америку, через океаны - и приходят, через период времени. Пока данных нет, код заблокирован. Он ждет, пока они появятся, чтобы их вычитать. А ведь вместо этого мы могли бы заняться чем-то полезным во время ожидания: распарсить другой сайт, сходить на другой домен и т.д.
